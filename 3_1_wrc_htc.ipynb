{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24a8dcd-88f7-4b0f-8cfd-a8b687df7746",
   "metadata": {},
   "source": [
    "## 准备预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eef69095-3a96-4760-9a7a-3aee99804ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma-user/work/wrc_htc/pre\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/wrc_htc/pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef77b5f-b015-4c2a-920d-bbc7d624bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htc_r50_fpn_20e_coco\n",
    "!wget -c https://download.openmmlab.com/mmdetection/v2.0/htc/htc_r50_fpn_20e_coco/htc_r50_fpn_20e_coco_20200319-fe28c577.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b9556-678e-4116-b505-59f831c84b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htc_r101_fpn_20e_coco\n",
    "!wget -c https://download.openmmlab.com/mmdetection/v2.0/htc/htc_r101_fpn_20e_coco/htc_r101_fpn_20e_coco_20200317-9b41b48f.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10469bac-1ef2-4d0b-a44a-de5fc56e9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htc_x101_64x4d_fpn_16x1_20e_coco\n",
    "!wget -c https://download.openmmlab.com/mmdetection/v2.0/htc/htc_x101_64x4d_fpn_16x1_20e_coco/htc_x101_64x4d_fpn_16x1_20e_coco_20200318-b181fd7a.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee0cd3-78fe-4ec4-9191-03a0505995f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco\n",
    "!wget -c https://download.openmmlab.com/mmdetection/v2.0/htc/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco/htc_x101_64x4d_fpn_dconv_c3-c5_mstrain_400_1400_16x1_20e_coco_20200312-946fd751.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b0444",
   "metadata": {},
   "source": [
    "## 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4e2b33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Collecting mmcv-full==1.2.4\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/19/b0/8598b2ed3d44d2d977f8c126b39d88acdcd37cf574d946f62d894fbac141/mmcv-full-1.2.4.tar.gz (216 kB)\n",
      "\u001b[K     |████████████████████████████████| 216 kB 71.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: addict in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from mmcv-full==1.2.4) (2.4.0)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from mmcv-full==1.2.4) (1.17.0)\n",
      "Requirement already satisfied: Pillow in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from mmcv-full==1.2.4) (6.2.0)\n",
      "Requirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from mmcv-full==1.2.4) (5.1)\n",
      "Requirement already satisfied: yapf in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from mmcv-full==1.2.4) (0.32.0)\n",
      "Building wheels for collected packages: mmcv-full\n",
      "  Building wheel for mmcv-full (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mmcv-full: filename=mmcv_full-1.2.4-cp37-cp37m-linux_x86_64.whl size=19019754 sha256=307b976261f2c557f3092c1846455355da8fe171b12d940b87a354c940a3d653\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/c9/30/dc/65f87e73685a68de6b2aac7ab5773070005ac28e98db880737\n",
      "Successfully built mmcv-full\n",
      "Installing collected packages: mmcv-full\n",
      "Successfully installed mmcv-full-1.2.4\n",
      "\u001b[33mWARNING: You are using pip version 21.2.2; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.4/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: terminaltables in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (3.1.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.2; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.4/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: pycocotools in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (2.0.4)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from pycocotools) (3.5.1)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from pycocotools) (1.17.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (4.33.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (6.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (4.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.2; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.4/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mmcv-full==1.2.4 #安装需要一段时间，请耐心等待，大概需要20min\n",
    "!pip install terminaltables\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b90c3",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma-user/work/wrc_htc/mmdetection\n",
      "2022-07-16 18:59:06,332 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.7.10 (default, Jun  4 2021, 14:48:32) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0: Tesla P100-PCIE-16GB\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PyTorch: 1.4.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "TorchVision: 0.5.0\n",
      "OpenCV: 4.1.2\n",
      "MMCV: 1.2.4\n",
      "MMCV Compiler: GCC 7.5\n",
      "MMCV CUDA Compiler: 10.1\n",
      "MMDetection: 2.11.0+2a20e69\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-07-16 18:59:07,438 - mmdet - INFO - Distributed training: False\n",
      "2022-07-16 18:59:08,579 - mmdet - INFO - Config:\n",
      "dataset_type = 'CocoDataset'\n",
      "classes = ('_background_', '1', '2', '3', '4', '5', '6')\n",
      "data_root = '/home/ma-user/work/wrc_htc/data/dataset_coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[63.10272151, 96.87820338, 76.34496829],\n",
      "    std=[24.33635513, 23.11288992, 31.79807813],\n",
      "    to_rgb=False)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[63.10272151, 96.87820338, 76.34496829],\n",
      "        std=[24.33635513, 23.11288992, 31.79807813],\n",
      "        to_rgb=False),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='SegRescale', scale_factor=0.125),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(\n",
      "        type='Collect',\n",
      "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[63.10272151, 96.87820338, 76.34496829],\n",
      "                std=[24.33635513, 23.11288992, 31.79807813],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=1,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('_background_', '1', '2', '3', '4', '5', '6'),\n",
      "        ann_file=\n",
      "        '/home/ma-user/work/wrc_htc/data/dataset_coco/annotations_train.json',\n",
      "        img_prefix='/home/ma-user/work/wrc_htc/data/dataset_coco/images/',\n",
      "        seg_prefix=\n",
      "        '/home/ma-user/work/wrc_htc/data/dataset_coco/stuffthingmaps',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                with_seg=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[63.10272151, 96.87820338, 76.34496829],\n",
      "                std=[24.33635513, 23.11288992, 31.79807813],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='SegRescale', scale_factor=0.125),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_masks',\n",
      "                    'gt_semantic_seg'\n",
      "                ])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('_background_', '1', '2', '3', '4', '5', '6'),\n",
      "        ann_file=\n",
      "        '/home/ma-user/work/wrc_htc/data/dataset_coco/annotations_val.json',\n",
      "        img_prefix='/home/ma-user/work/wrc_htc/data/dataset_coco/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[63.10272151, 96.87820338, 76.34496829],\n",
      "                        std=[24.33635513, 23.11288992, 31.79807813],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('_background_', '1', '2', '3', '4', '5', '6'),\n",
      "        ann_file=\n",
      "        '/home/ma-user/work/wrc_htc/data/dataset_coco/annotations_val.json',\n",
      "        img_prefix='/home/ma-user/work/wrc_htc/data/dataset_coco/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[63.10272151, 96.87820338, 76.34496829],\n",
      "                        std=[24.33635513, 23.11288992, 31.79807813],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(metric=['bbox', 'segm'], save_best='auto')\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[16, 19])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=20)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '/home/ma-user/work/wrc_htc/pre/htc_r50_fpn_20e_coco_20200319-fe28c577.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "model = dict(\n",
      "    type='HybridTaskCascade',\n",
      "    pretrained='torchvision://resnet50',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_eval=True,\n",
      "        style='pytorch'),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='HybridTaskCascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[1, 0.5, 0.25],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=7,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=7,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=7,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
      "        ],\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=[\n",
      "            dict(\n",
      "                type='HTCMaskHead',\n",
      "                with_conv_res=False,\n",
      "                num_convs=4,\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                num_classes=7,\n",
      "                loss_mask=dict(\n",
      "                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='HTCMaskHead',\n",
      "                num_convs=4,\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                num_classes=7,\n",
      "                loss_mask=dict(\n",
      "                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='HTCMaskHead',\n",
      "                num_convs=4,\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                num_classes=7,\n",
      "                loss_mask=dict(\n",
      "                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))\n",
      "        ],\n",
      "        semantic_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[8]),\n",
      "        semantic_head=dict(\n",
      "            type='FusedSemanticHead',\n",
      "            num_ins=5,\n",
      "            fusion_level=1,\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=183,\n",
      "            ignore_label=255,\n",
      "            loss_weight=0.2)),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                debug=False)\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.001,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "work_dir = '/home/ma-user/work/wrc_htc/ckpt/'\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "2022-07-16 18:59:09,285 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2022-07-16 18:59:09,585 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-07-16 18:59:12,207 - mmdet - INFO - load checkpoint from /home/ma-user/work/wrc_htc/pre/htc_r50_fpn_20e_coco_20200319-fe28c577.pth\n",
      "2022-07-16 18:59:12,836 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n",
      "size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n",
      "size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n",
      "size mismatch for roi_head.bbox_head.2.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "size mismatch for roi_head.mask_head.0.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([7, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.0.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "size mismatch for roi_head.mask_head.1.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([7, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.1.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "size mismatch for roi_head.mask_head.2.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([7, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.2.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2022-07-16 18:59:12,866 - mmdet - INFO - Start running, host: ma-user@kg-c4f2050c-4cf9-496c-a00c-369954cf05d6, work_dir: /home/ma-user/work/wrc_htc/ckpt\n",
      "2022-07-16 18:59:12,866 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
      "2022-07-16 18:59:39,317 - mmdet - INFO - Epoch [1][50/851]\tlr: 2.473e-04, eta: 2:29:31, time: 0.529, data_time: 0.051, memory: 3215, loss_rpn_cls: 0.0720, loss_rpn_bbox: 0.0132, loss_semantic_seg: 0.9847, s0.loss_cls: 1.0631, s0.acc: 79.5273, s0.loss_bbox: 0.0310, s0.loss_mask: 1.6633, s1.loss_cls: 0.5494, s1.acc: 84.9102, s1.loss_bbox: 0.0144, s1.loss_mask: 1.8088, s2.loss_cls: 0.3162, s2.acc: 59.7500, s2.loss_bbox: 0.0050, s2.loss_mask: 0.8001, loss: 7.3211, grad_norm: 66.8233\n",
      "2022-07-16 19:00:04,066 - mmdet - INFO - Epoch [1][100/851]\tlr: 4.970e-04, eta: 2:24:21, time: 0.495, data_time: 0.008, memory: 3306, loss_rpn_cls: 0.0472, loss_rpn_bbox: 0.0155, loss_semantic_seg: 0.1559, s0.loss_cls: 0.2024, s0.acc: 96.8203, s0.loss_bbox: 0.0546, s0.loss_mask: 0.5739, s1.loss_cls: 0.0850, s1.acc: 97.5156, s1.loss_bbox: 0.0316, s1.loss_mask: 0.2822, s2.loss_cls: 0.0358, s2.acc: 98.1289, s2.loss_bbox: 0.0111, s2.loss_mask: 0.1336, loss: 1.6288, grad_norm: 10.0333\n",
      "2022-07-16 19:00:30,879 - mmdet - INFO - Epoch [1][150/851]\tlr: 7.468e-04, eta: 2:26:12, time: 0.536, data_time: 0.008, memory: 4020, loss_rpn_cls: 0.0129, loss_rpn_bbox: 0.0130, loss_semantic_seg: 0.1042, s0.loss_cls: 0.1931, s0.acc: 95.0352, s0.loss_bbox: 0.0363, s0.loss_mask: 0.4068, s1.loss_cls: 0.1177, s1.acc: 94.0820, s1.loss_bbox: 0.0404, s1.loss_mask: 0.2124, s2.loss_cls: 0.0679, s2.acc: 94.0898, s2.loss_bbox: 0.0258, s2.loss_mask: 0.1053, loss: 1.3358, grad_norm: 8.5907\n",
      "2022-07-16 19:00:58,917 - mmdet - INFO - Epoch [1][200/851]\tlr: 9.965e-04, eta: 2:28:37, time: 0.561, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0052, loss_semantic_seg: 0.0639, s0.loss_cls: 0.1605, s0.acc: 94.6758, s0.loss_bbox: 0.0286, s0.loss_mask: 0.3248, s1.loss_cls: 0.1038, s1.acc: 93.2500, s1.loss_bbox: 0.0366, s1.loss_mask: 0.1694, s2.loss_cls: 0.0663, s2.acc: 91.6055, s2.loss_bbox: 0.0304, s2.loss_mask: 0.0852, loss: 1.0814, grad_norm: 8.2704\n",
      "2022-07-16 19:01:27,412 - mmdet - INFO - Epoch [1][250/851]\tlr: 1.246e-03, eta: 2:30:24, time: 0.570, data_time: 0.010, memory: 4406, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0093, loss_semantic_seg: 0.0516, s0.loss_cls: 0.1223, s0.acc: 95.3438, s0.loss_bbox: 0.0288, s0.loss_mask: 0.3083, s1.loss_cls: 0.0804, s1.acc: 93.6758, s1.loss_bbox: 0.0359, s1.loss_mask: 0.1645, s2.loss_cls: 0.0516, s2.acc: 92.6328, s2.loss_bbox: 0.0317, s2.loss_mask: 0.0916, loss: 0.9785, grad_norm: 7.9142\n",
      "2022-07-16 19:01:54,552 - mmdet - INFO - Epoch [1][300/851]\tlr: 1.496e-03, eta: 2:30:10, time: 0.543, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0076, loss_semantic_seg: 0.0365, s0.loss_cls: 0.0922, s0.acc: 96.4531, s0.loss_bbox: 0.0191, s0.loss_mask: 0.2722, s1.loss_cls: 0.0590, s1.acc: 95.5234, s1.loss_bbox: 0.0311, s1.loss_mask: 0.1440, s2.loss_cls: 0.0386, s2.acc: 94.2188, s2.loss_bbox: 0.0253, s2.loss_mask: 0.0762, loss: 0.8093, grad_norm: 7.3725\n",
      "2022-07-16 19:02:22,730 - mmdet - INFO - Epoch [1][350/851]\tlr: 1.746e-03, eta: 2:30:42, time: 0.564, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0111, loss_semantic_seg: 0.0378, s0.loss_cls: 0.0891, s0.acc: 97.0664, s0.loss_bbox: 0.0281, s0.loss_mask: 0.2951, s1.loss_cls: 0.0549, s1.acc: 96.3281, s1.loss_bbox: 0.0404, s1.loss_mask: 0.1472, s2.loss_cls: 0.0365, s2.acc: 94.7422, s2.loss_bbox: 0.0320, s2.loss_mask: 0.0793, loss: 0.8587, grad_norm: 9.6517\n",
      "2022-07-16 19:02:52,351 - mmdet - INFO - Epoch [1][400/851]\tlr: 1.996e-03, eta: 2:31:59, time: 0.592, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0128, loss_semantic_seg: 0.0366, s0.loss_cls: 0.0798, s0.acc: 96.9883, s0.loss_bbox: 0.0316, s0.loss_mask: 0.2522, s1.loss_cls: 0.0522, s1.acc: 95.9570, s1.loss_bbox: 0.0415, s1.loss_mask: 0.1446, s2.loss_cls: 0.0354, s2.acc: 94.5391, s2.loss_bbox: 0.0335, s2.loss_mask: 0.0764, loss: 0.8046, grad_norm: 8.1477\n",
      "2022-07-16 19:03:19,255 - mmdet - INFO - Epoch [1][450/851]\tlr: 2.245e-03, eta: 2:31:12, time: 0.538, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0080, loss_semantic_seg: 0.0406, s0.loss_cls: 0.0773, s0.acc: 97.3516, s0.loss_bbox: 0.0255, s0.loss_mask: 0.2799, s1.loss_cls: 0.0457, s1.acc: 96.8750, s1.loss_bbox: 0.0265, s1.loss_mask: 0.1913, s2.loss_cls: 0.0284, s2.acc: 96.3750, s2.loss_bbox: 0.0205, s2.loss_mask: 0.0887, loss: 0.8379, grad_norm: 9.5711\n",
      "2022-07-16 19:03:46,477 - mmdet - INFO - Epoch [1][500/851]\tlr: 2.495e-03, eta: 2:30:39, time: 0.544, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0066, loss_semantic_seg: 0.0398, s0.loss_cls: 0.0754, s0.acc: 97.5781, s0.loss_bbox: 0.0238, s0.loss_mask: 0.2917, s1.loss_cls: 0.0468, s1.acc: 97.2539, s1.loss_bbox: 0.0296, s1.loss_mask: 0.1709, s2.loss_cls: 0.0294, s2.acc: 96.2070, s2.loss_bbox: 0.0224, s2.loss_mask: 0.0864, loss: 0.8298, grad_norm: 5.1208\n",
      "2022-07-16 19:04:14,370 - mmdet - INFO - Epoch [1][550/851]\tlr: 2.500e-03, eta: 2:30:28, time: 0.558, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0109, loss_rpn_bbox: 0.0058, loss_semantic_seg: 0.0307, s0.loss_cls: 0.0643, s0.acc: 98.1406, s0.loss_bbox: 0.0211, s0.loss_mask: 0.2368, s1.loss_cls: 0.0413, s1.acc: 97.8125, s1.loss_bbox: 0.0290, s1.loss_mask: 0.1340, s2.loss_cls: 0.0278, s2.acc: 96.7773, s2.loss_bbox: 0.0257, s2.loss_mask: 0.0701, loss: 0.6975, grad_norm: 5.9596\n",
      "2022-07-16 19:04:43,452 - mmdet - INFO - Epoch [1][600/851]\tlr: 2.500e-03, eta: 2:30:46, time: 0.582, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0061, loss_semantic_seg: 0.0269, s0.loss_cls: 0.0540, s0.acc: 98.2422, s0.loss_bbox: 0.0220, s0.loss_mask: 0.1933, s1.loss_cls: 0.0341, s1.acc: 97.7383, s1.loss_bbox: 0.0331, s1.loss_mask: 0.1000, s2.loss_cls: 0.0247, s2.acc: 96.5469, s2.loss_bbox: 0.0291, s2.loss_mask: 0.0557, loss: 0.5838, grad_norm: 5.3769\n",
      "2022-07-16 19:05:10,712 - mmdet - INFO - Epoch [1][650/851]\tlr: 2.500e-03, eta: 2:30:11, time: 0.545, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0053, loss_semantic_seg: 0.0347, s0.loss_cls: 0.0513, s0.acc: 98.4062, s0.loss_bbox: 0.0240, s0.loss_mask: 0.2323, s1.loss_cls: 0.0315, s1.acc: 98.0781, s1.loss_bbox: 0.0319, s1.loss_mask: 0.1234, s2.loss_cls: 0.0213, s2.acc: 97.4453, s2.loss_bbox: 0.0230, s2.loss_mask: 0.0679, loss: 0.6516, grad_norm: 7.5089\n",
      "2022-07-16 19:05:37,980 - mmdet - INFO - Epoch [1][700/851]\tlr: 2.500e-03, eta: 2:29:38, time: 0.545, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0095, loss_rpn_bbox: 0.0119, loss_semantic_seg: 0.0276, s0.loss_cls: 0.0511, s0.acc: 98.4180, s0.loss_bbox: 0.0226, s0.loss_mask: 0.2511, s1.loss_cls: 0.0330, s1.acc: 98.0078, s1.loss_bbox: 0.0307, s1.loss_mask: 0.1357, s2.loss_cls: 0.0229, s2.acc: 97.2031, s2.loss_bbox: 0.0244, s2.loss_mask: 0.0686, loss: 0.6889, grad_norm: 4.8538\n",
      "2022-07-16 19:06:06,258 - mmdet - INFO - Epoch [1][750/851]\tlr: 2.500e-03, eta: 2:29:27, time: 0.566, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0042, loss_semantic_seg: 0.0245, s0.loss_cls: 0.0512, s0.acc: 98.3945, s0.loss_bbox: 0.0202, s0.loss_mask: 0.2131, s1.loss_cls: 0.0330, s1.acc: 98.0898, s1.loss_bbox: 0.0321, s1.loss_mask: 0.1110, s2.loss_cls: 0.0219, s2.acc: 97.1602, s2.loss_bbox: 0.0295, s2.loss_mask: 0.0568, loss: 0.6023, grad_norm: 5.4051\n",
      "2022-07-16 19:06:34,209 - mmdet - INFO - Epoch [1][800/851]\tlr: 2.500e-03, eta: 2:29:07, time: 0.559, data_time: 0.007, memory: 4406, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0043, loss_semantic_seg: 0.0282, s0.loss_cls: 0.0547, s0.acc: 98.1758, s0.loss_bbox: 0.0223, s0.loss_mask: 0.2147, s1.loss_cls: 0.0359, s1.acc: 97.7109, s1.loss_bbox: 0.0322, s1.loss_mask: 0.1113, s2.loss_cls: 0.0238, s2.acc: 96.8984, s2.loss_bbox: 0.0280, s2.loss_mask: 0.0569, loss: 0.6143, grad_norm: 6.6356\n",
      "2022-07-16 19:07:02,135 - mmdet - INFO - Epoch [1][850/851]\tlr: 2.500e-03, eta: 2:28:46, time: 0.559, data_time: 0.008, memory: 4406, loss_rpn_cls: 0.0114, loss_rpn_bbox: 0.0063, loss_semantic_seg: 0.0225, s0.loss_cls: 0.0482, s0.acc: 98.5312, s0.loss_bbox: 0.0210, s0.loss_mask: 0.1684, s1.loss_cls: 0.0325, s1.acc: 98.1406, s1.loss_bbox: 0.0343, s1.loss_mask: 0.0889, s2.loss_cls: 0.0227, s2.acc: 97.4453, s2.loss_bbox: 0.0307, s2.loss_mask: 0.0486, loss: 0.5354, grad_norm: 4.1942\n",
      "2022-07-16 19:07:02,806 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 314/314, 2.7 task/s, elapsed: 116s, ETA:     0s2022-07-16 19:09:02,305 - mmdet - INFO - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.87s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.48s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.544\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.490\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.475\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.414\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.771\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.771\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.771\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.702\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.845\n",
      "2022-07-16 19:09:03,840 - mmdet - INFO - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=1.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.47s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.538\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.493\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.550\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.491\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.798\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.798\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.798\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.550\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.687\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.876\n",
      "2022-07-16 19:09:05,738 - mmdet - INFO - Now best checkpoint is epoch_1.pth.Best bbox_mAP is 0.4060\n",
      "2022-07-16 19:09:05,748 - mmdet - INFO - Exp name: htc_wrc.py\n",
      "2022-07-16 19:09:05,749 - mmdet - INFO - Epoch(val) [1][851]\tbbox_mAP: 0.4060, bbox_mAP_50: 0.5440, bbox_mAP_75: 0.4900, bbox_mAP_s: 0.4750, bbox_mAP_m: 0.4140, bbox_mAP_l: 0.4740, bbox_mAP_copypaste: 0.406 0.544 0.490 0.475 0.414 0.474, segm_mAP: 0.4250, segm_mAP_50: 0.5380, segm_mAP_75: 0.4930, segm_mAP_s: 0.5500, segm_mAP_m: 0.3870, segm_mAP_l: 0.4910, segm_mAP_copypaste: 0.425 0.538 0.493 0.550 0.387 0.491\n",
      "2022-07-16 19:09:35,108 - mmdet - INFO - Epoch [2][50/851]\tlr: 2.500e-03, eta: 2:28:40, time: 0.587, data_time: 0.050, memory: 4406, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0059, loss_semantic_seg: 0.0186, s0.loss_cls: 0.0437, s0.acc: 98.6211, s0.loss_bbox: 0.0210, s0.loss_mask: 0.1779, s1.loss_cls: 0.0288, s1.acc: 98.2578, s1.loss_bbox: 0.0321, s1.loss_mask: 0.0943, s2.loss_cls: 0.0211, s2.acc: 97.1055, s2.loss_bbox: 0.0283, s2.loss_mask: 0.0523, loss: 0.5276, grad_norm: 4.2129\n",
      "2022-07-16 19:10:03,714 - mmdet - INFO - Epoch [2][100/851]\tlr: 2.500e-03, eta: 2:28:28, time: 0.572, data_time: 0.008, memory: 4532, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0061, loss_semantic_seg: 0.0252, s0.loss_cls: 0.0500, s0.acc: 98.5938, s0.loss_bbox: 0.0192, s0.loss_mask: 0.1621, s1.loss_cls: 0.0306, s1.acc: 98.3320, s1.loss_bbox: 0.0315, s1.loss_mask: 0.0820, s2.loss_cls: 0.0200, s2.acc: 97.5469, s2.loss_bbox: 0.0318, s2.loss_mask: 0.0453, loss: 0.5071, grad_norm: 4.0331\n",
      "2022-07-16 19:10:31,723 - mmdet - INFO - Epoch [2][150/851]\tlr: 2.500e-03, eta: 2:28:05, time: 0.560, data_time: 0.008, memory: 4532, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0076, loss_semantic_seg: 0.0172, s0.loss_cls: 0.0431, s0.acc: 98.6445, s0.loss_bbox: 0.0164, s0.loss_mask: 0.1610, s1.loss_cls: 0.0287, s1.acc: 98.1562, s1.loss_bbox: 0.0253, s1.loss_mask: 0.0835, s2.loss_cls: 0.0189, s2.acc: 97.8008, s2.loss_bbox: 0.0240, s2.loss_mask: 0.0460, loss: 0.4795, grad_norm: 4.8853\n",
      "2022-07-16 19:11:00,166 - mmdet - INFO - Epoch [2][200/851]\tlr: 2.500e-03, eta: 2:27:48, time: 0.569, data_time: 0.008, memory: 4532, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0082, loss_semantic_seg: 0.0211, s0.loss_cls: 0.0425, s0.acc: 98.5508, s0.loss_bbox: 0.0167, s0.loss_mask: 0.1560, s1.loss_cls: 0.0286, s1.acc: 98.2656, s1.loss_bbox: 0.0241, s1.loss_mask: 0.0859, s2.loss_cls: 0.0203, s2.acc: 97.2266, s2.loss_bbox: 0.0277, s2.loss_mask: 0.0451, loss: 0.4798, grad_norm: 3.7957\n",
      "2022-07-16 19:11:29,064 - mmdet - INFO - Epoch [2][250/851]\tlr: 2.500e-03, eta: 2:27:36, time: 0.578, data_time: 0.008, memory: 4567, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0069, loss_semantic_seg: 0.0181, s0.loss_cls: 0.0387, s0.acc: 98.5430, s0.loss_bbox: 0.0175, s0.loss_mask: 0.1708, s1.loss_cls: 0.0266, s1.acc: 98.3320, s1.loss_bbox: 0.0291, s1.loss_mask: 0.0837, s2.loss_cls: 0.0192, s2.acc: 97.6367, s2.loss_bbox: 0.0286, s2.loss_mask: 0.0438, loss: 0.4857, grad_norm: 4.0783\n",
      "2022-07-16 19:11:56,520 - mmdet - INFO - Epoch [2][300/851]\tlr: 2.500e-03, eta: 2:27:03, time: 0.549, data_time: 0.007, memory: 4567, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0082, loss_semantic_seg: 0.0188, s0.loss_cls: 0.0434, s0.acc: 98.4805, s0.loss_bbox: 0.0191, s0.loss_mask: 0.1798, s1.loss_cls: 0.0306, s1.acc: 97.7344, s1.loss_bbox: 0.0278, s1.loss_mask: 0.0878, s2.loss_cls: 0.0212, s2.acc: 96.7930, s2.loss_bbox: 0.0242, s2.loss_mask: 0.0439, loss: 0.5076, grad_norm: 4.4763\n",
      "2022-07-16 19:12:24,202 - mmdet - INFO - Epoch [2][350/851]\tlr: 2.500e-03, eta: 2:26:34, time: 0.554, data_time: 0.007, memory: 4567, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0035, loss_semantic_seg: 0.0179, s0.loss_cls: 0.0453, s0.acc: 98.6172, s0.loss_bbox: 0.0168, s0.loss_mask: 0.1498, s1.loss_cls: 0.0318, s1.acc: 98.1719, s1.loss_bbox: 0.0269, s1.loss_mask: 0.0783, s2.loss_cls: 0.0219, s2.acc: 97.2969, s2.loss_bbox: 0.0237, s2.loss_mask: 0.0421, loss: 0.4603, grad_norm: 3.4522\n",
      "2022-07-16 19:12:53,155 - mmdet - INFO - Epoch [2][400/851]\tlr: 2.500e-03, eta: 2:26:21, time: 0.579, data_time: 0.008, memory: 4567, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0065, loss_semantic_seg: 0.0172, s0.loss_cls: 0.0437, s0.acc: 98.7773, s0.loss_bbox: 0.0166, s0.loss_mask: 0.1467, s1.loss_cls: 0.0291, s1.acc: 98.4805, s1.loss_bbox: 0.0317, s1.loss_mask: 0.0768, s2.loss_cls: 0.0200, s2.acc: 97.9141, s2.loss_bbox: 0.0295, s2.loss_mask: 0.0401, loss: 0.4616, grad_norm: 3.4973\n",
      "2022-07-16 19:13:21,787 - mmdet - INFO - Epoch [2][450/851]\tlr: 2.500e-03, eta: 2:26:03, time: 0.573, data_time: 0.008, memory: 4567, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0050, loss_semantic_seg: 0.0194, s0.loss_cls: 0.0369, s0.acc: 98.7969, s0.loss_bbox: 0.0148, s0.loss_mask: 0.1757, s1.loss_cls: 0.0253, s1.acc: 98.4023, s1.loss_bbox: 0.0251, s1.loss_mask: 0.0898, s2.loss_cls: 0.0175, s2.acc: 97.5508, s2.loss_bbox: 0.0242, s2.loss_mask: 0.0459, loss: 0.4820, grad_norm: 3.4877\n",
      "2022-07-16 19:13:50,107 - mmdet - INFO - Epoch [2][500/851]\tlr: 2.500e-03, eta: 2:25:40, time: 0.566, data_time: 0.008, memory: 4567, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0058, loss_semantic_seg: 0.0181, s0.loss_cls: 0.0446, s0.acc: 98.6250, s0.loss_bbox: 0.0178, s0.loss_mask: 0.1542, s1.loss_cls: 0.0306, s1.acc: 98.2266, s1.loss_bbox: 0.0274, s1.loss_mask: 0.0798, s2.loss_cls: 0.0213, s2.acc: 97.1797, s2.loss_bbox: 0.0248, s2.loss_mask: 0.0403, loss: 0.4668, grad_norm: 3.6783\n",
      "2022-07-16 19:14:18,979 - mmdet - INFO - Epoch [2][550/851]\tlr: 2.500e-03, eta: 2:25:23, time: 0.577, data_time: 0.008, memory: 4592, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0053, loss_semantic_seg: 0.0176, s0.loss_cls: 0.0432, s0.acc: 98.6055, s0.loss_bbox: 0.0206, s0.loss_mask: 0.1452, s1.loss_cls: 0.0322, s1.acc: 98.0039, s1.loss_bbox: 0.0301, s1.loss_mask: 0.0782, s2.loss_cls: 0.0227, s2.acc: 97.1484, s2.loss_bbox: 0.0290, s2.loss_mask: 0.0418, loss: 0.4694, grad_norm: 3.2866\n",
      "2022-07-16 19:14:47,706 - mmdet - INFO - Epoch [2][600/851]\tlr: 2.500e-03, eta: 2:25:04, time: 0.575, data_time: 0.008, memory: 4592, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0023, loss_semantic_seg: 0.0145, s0.loss_cls: 0.0402, s0.acc: 98.7461, s0.loss_bbox: 0.0181, s0.loss_mask: 0.1507, s1.loss_cls: 0.0311, s1.acc: 97.9766, s1.loss_bbox: 0.0302, s1.loss_mask: 0.0801, s2.loss_cls: 0.0225, s2.acc: 97.0742, s2.loss_bbox: 0.0284, s2.loss_mask: 0.0434, loss: 0.4631, grad_norm: 3.4855\n",
      "2022-07-16 19:15:16,610 - mmdet - INFO - Epoch [2][650/851]\tlr: 2.500e-03, eta: 2:24:45, time: 0.578, data_time: 0.008, memory: 4592, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0023, loss_semantic_seg: 0.0157, s0.loss_cls: 0.0481, s0.acc: 98.4336, s0.loss_bbox: 0.0173, s0.loss_mask: 0.1549, s1.loss_cls: 0.0350, s1.acc: 97.6133, s1.loss_bbox: 0.0281, s1.loss_mask: 0.0826, s2.loss_cls: 0.0232, s2.acc: 96.6445, s2.loss_bbox: 0.0295, s2.loss_mask: 0.0426, loss: 0.4816, grad_norm: 4.5154\n",
      "2022-07-16 19:15:45,203 - mmdet - INFO - Epoch [2][700/851]\tlr: 2.500e-03, eta: 2:24:23, time: 0.572, data_time: 0.008, memory: 4592, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0042, loss_semantic_seg: 0.0157, s0.loss_cls: 0.0358, s0.acc: 98.8594, s0.loss_bbox: 0.0176, s0.loss_mask: 0.1391, s1.loss_cls: 0.0241, s1.acc: 98.6172, s1.loss_bbox: 0.0215, s1.loss_mask: 0.0716, s2.loss_cls: 0.0166, s2.acc: 97.7031, s2.loss_bbox: 0.0237, s2.loss_mask: 0.0377, loss: 0.4103, grad_norm: 3.3791\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/wrc_htc/mmdetection/\n",
    "!python ./tools/train.py configs/htc/htc_wrc.py --work-dir \"/home/ma-user/work/wrc_htc/ckpt/\""
   ]
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "768f1e56-90ac-483e-abd4-5d741c669f6b"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54099",
   "name": "pytorch1.4-cuda10.1-cudnn7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
